{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, Blip2ForConditionalGeneration\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelPreparation(modelCheckpoint):    \n",
    "    processor = AutoProcessor.from_pretrained(modelCheckpoint)\n",
    "    model = Blip2ForConditionalGeneration.from_pretrained(modelCheckpoint,torch_dtype=torch.float16)\n",
    "    return  model.to(device),processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1947157fda4547ac918c631e6314b80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelCheckpoint = \"Salesforce/blip2-opt-2.7b\"\n",
    "model,processor = modelPreparation(modelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dog is sleeping in a basket of shoes\n"
     ]
    }
   ],
   "source": [
    "def showimage(image,show=False):\n",
    "    image = Image.open(image).convert('RGB')\n",
    "    if show:\n",
    "        display(image.resize((596,437)))\n",
    "    return image\n",
    "    \n",
    "\n",
    "def normalCaptioning(model,processor,image):\n",
    "    image = showimage(image)\n",
    "    inputs = processor(image,return_tensors=\"pt\").to(device,torch.float16)\n",
    "    ids = model.generate(**inputs,max_new_tokens=50)\n",
    "    caption = processor.batch_decode(ids,skip_special_tokens=True)[0].strip()\n",
    "    return caption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def promptedCaptioning(model,processor,prompt,image):\n",
    "    image= showimage(image)\n",
    "    inputs = processor(image,text=prompt,return_tensors=\"pt\").to(device, torch.float16)\n",
    "    ids = model.generate(**inputs,max_new_tokens=100)\n",
    "    caption = processor.batch_decode(ids,skip_special_tokens=True)[0].strip()\n",
    "    return caption\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two horses grazing in a field\n"
     ]
    }
   ],
   "source": [
    "image = '../data/val2014/COCO_val2014_000000546095.jpg'\n",
    "# caption = normalCaptioning(model,processor,image)\n",
    "# print(caption)\n",
    "prompt = 'image of'\n",
    "caption = promptedCaptioning(model,processor,prompt,image)\n",
    "print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['img', 'caption', 'question', 'label_answer'])\n",
      "   gold_answer            predicted_answer\n",
      "0   dandelions                     daisies\n",
      "1      nothing                  A suitcase\n",
      "2           no                         Yes\n",
      "3           no  Yes, they are in a bathtub\n",
      "4           no          No, this is a ship\n",
      "5        white                       white\n",
      "6           no                         yes\n",
      "7          yes                         Yes\n",
      "8            2                           1\n",
      "9           no                         yes\n",
      "10      turkey                    a turkey\n",
      "11        male                        Male\n",
      "12         yes                         Yes\n",
      "13         yes                         Yes\n",
      "14         yes                         Yes\n",
      "15       black                       green\n",
      "16         cat                     the cat\n",
      "17     chicken      Broccoli and mushrooms\n",
      "18      skiing                      Skiing\n",
      "19        gray                       Black\n"
     ]
    }
   ],
   "source": [
    "d = {\"id\":[],\"caption\":[],\"question\":[],\"gold_answer\":[],\"predicted_answer\":[]}\n",
    "with open('../data/blip2_vqav2_images_data_sampled.json', 'r') as fcc:\n",
    "    data = json.load(fcc)\n",
    "    print(data['546095005'].keys())\n",
    "    for k in data.keys():\n",
    "        q = data[k]['question']\n",
    "        image = '../data/val2014/'+data[k]['img'].split('/')[-1]\n",
    "        prompt =q+' ,Answer:'\n",
    "        predAns = promptedCaptioning(model,processor,prompt,image)\n",
    "        d[\"id\"].append(k)\n",
    "        d[\"caption\"].append(data[k]['caption'])\n",
    "        d[\"question\"].append(q)\n",
    "        d[\"gold_answer\"].append(data[k]['label_answer'])\n",
    "        d[\"predicted_answer\"].append(predAns)\n",
    "       \n",
    "        \n",
    "    df = pd.DataFrame(d).reset_index() \n",
    "    print(df[[\"gold_answer\",\"predicted_answer\"]])\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
